{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "!pip install -r requirements.txt\n",
    "# Các bạn có thể chạy dòng lệnh này trên terminal, nhưng phải bỏ dấu ! ở đầu câu lệnh đi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-4 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 1142.2ms pre-process, 250.6ms inference, 12.9ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n",
    "\n",
    "# Images\n",
    "img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "\n",
    "# Results\n",
    "results.print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/2 E:\\AI_ML_DL\\Yolo\\yolov5\\data\\images\\bus.jpg: 640x480 4 persons, 1 bus, 327.1ms\n",
      "image 2/2 E:\\AI_ML_DL\\Yolo\\yolov5\\data\\images\\zidane.jpg: 384x640 2 persons, 2 ties, 254.3ms\n",
      "Speed: 1.8ms pre-process, 290.7ms inference, 6.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Detect từ các ảnh có trong folder data/images\n",
    "# Các bạn có thể cho ảnh khác vào folder đó để thử\n",
    "!python detect.py --source data/images --weights yolov5s.pt --conf 0.25\n",
    "# Nếu các bạn cài đặt thành công GPU thì dòng thứ 5 ở phần kết quả bên dưới nó sẽ ghi tên GPU của bạn thay vì CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=0, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "0: 480x640 1 person, 306.6ms\n",
      "0: 480x640 1 person, 309.6ms\n",
      "0: 480x640 1 person, 303.0ms\n",
      "0: 480x640 1 person, 296.8ms\n",
      "0: 480x640 1 person, 284.1ms\n",
      "0: 480x640 1 person, 261.7ms\n",
      "0: 480x640 1 person, 287.1ms\n",
      "0: 480x640 1 person, 284.9ms\n",
      "0: 480x640 1 person, 290.4ms\n",
      "0: 480x640 1 person, 296.8ms\n",
      "0: 480x640 1 person, 292.5ms\n",
      "0: 480x640 1 person, 274.7ms\n",
      "0: 480x640 1 person, 283.3ms\n",
      "0: 480x640 1 person, 267.2ms\n",
      "0: 480x640 1 person, 284.0ms\n",
      "0: 480x640 1 person, 282.0ms\n",
      "0: 480x640 1 person, 288.7ms\n",
      "0: 480x640 1 person, 260.8ms\n",
      "0: 480x640 1 person, 285.6ms\n",
      "0: 480x640 1 person, 1 tie, 289.4ms\n",
      "0: 480x640 1 person, 259.3ms\n",
      "0: 480x640 1 person, 293.5ms\n",
      "0: 480x640 1 person, 1 laptop, 271.8ms\n",
      "0: 480x640 2 persons, 271.7ms\n",
      "0: 480x640 1 person, 1 remote, 283.3ms\n",
      "0: 480x640 1 person, 265.8ms\n",
      "0: 480x640 1 person, 279.2ms\n",
      "0: 480x640 1 person, 1 tie, 264.5ms\n",
      "0: 480x640 1 person, 291.8ms\n",
      "0: 480x640 1 person, 277.9ms\n",
      "0: 480x640 1 person, 273.0ms\n",
      "0: 480x640 1 person, 284.1ms\n",
      "0: 480x640 1 person, 279.0ms\n",
      "0: 480x640 1 person, 276.2ms\n",
      "0: 480x640 1 person, 285.3ms\n",
      "0: 480x640 1 person, 273.1ms\n",
      "0: 480x640 1 person, 261.6ms\n",
      "0: 480x640 1 person, 275.3ms\n",
      "0: 480x640 1 person, 263.1ms\n",
      "0: 480x640 1 person, 260.9ms\n",
      "0: 480x640 1 person, 253.2ms\n",
      "0: 480x640 1 person, 276.4ms\n",
      "0: 480x640 1 person, 262.3ms\n",
      "0: 480x640 1 person, 277.2ms\n",
      "0: 480x640 1 person, 281.1ms\n",
      "0: 480x640 1 person, 272.4ms\n",
      "0: 480x640 1 person, 279.0ms\n",
      "0: 480x640 1 person, 278.6ms\n",
      "0: 480x640 1 person, 276.4ms\n",
      "0: 480x640 1 person, 272.2ms\n",
      "0: 480x640 1 person, 266.8ms\n",
      "0: 480x640 1 person, 254.1ms\n",
      "0: 480x640 1 person, 252.3ms\n",
      "0: 480x640 1 person, 255.3ms\n",
      "0: 480x640 1 person, 273.3ms\n",
      "0: 480x640 1 person, 272.0ms\n",
      "0: 480x640 1 person, 272.3ms\n",
      "0: 480x640 1 person, 277.7ms\n",
      "0: 480x640 1 person, 261.4ms\n",
      "0: 480x640 1 person, 270.5ms\n",
      "0: 480x640 2 persons, 2 remotes, 311.0ms\n",
      "0: 480x640 1 person, 244.1ms\n",
      "0: 480x640 1 person, 270.7ms\n",
      "0: 480x640 1 person, 1 tie, 259.0ms\n",
      "0: 480x640 2 persons, 262.9ms\n",
      "0: 480x640 1 person, 271.8ms\n",
      "0: 480x640 1 person, 244.9ms\n",
      "0: 480x640 1 person, 265.0ms\n",
      "0: 480x640 1 person, 266.7ms\n",
      "0: 480x640 1 person, 1 remote, 253.7ms\n",
      "0: 480x640 1 person, 1 cell phone, 280.6ms\n",
      "0: 480x640 1 person, 1 cell phone, 283.7ms\n",
      "0: 480x640 1 person, 1 cell phone, 271.8ms\n",
      "0: 480x640 1 person, 1 cell phone, 277.5ms\n",
      "0: 480x640 1 person, 1 cell phone, 275.5ms\n",
      "0: 480x640 1 person, 1 cell phone, 267.3ms\n",
      "0: 480x640 1 person, 255.5ms\n",
      "0: 480x640 1 person, 275.8ms\n",
      "0: 480x640 1 person, 265.6ms\n",
      "0: 480x640 1 person, 266.3ms\n",
      "0: 480x640 1 person, 282.3ms\n",
      "0: 480x640 1 person, 264.9ms\n",
      "0: 480x640 1 person, 281.5ms\n",
      "0: 480x640 1 person, 293.4ms\n",
      "0: 480x640 1 person, 284.6ms\n",
      "0: 480x640 1 person, 283.5ms\n",
      "0: 480x640 1 person, 287.2ms\n",
      "0: 480x640 1 person, 269.6ms\n",
      "0: 480x640 1 person, 277.5ms\n",
      "0: 480x640 1 person, 274.7ms\n",
      "0: 480x640 1 person, 280.0ms\n",
      "0: 480x640 1 person, 318.3ms\n",
      "0: 480x640 1 person, 304.5ms\n",
      "0: 480x640 1 person, 281.2ms\n",
      "0: 480x640 1 person, 270.3ms\n",
      "0: 480x640 1 person, 283.4ms\n",
      "0: 480x640 1 person, 265.3ms\n",
      "0: 480x640 1 person, 274.3ms\n",
      "0: 480x640 1 person, 283.2ms\n",
      "0: 480x640 1 person, 270.3ms\n",
      "0: 480x640 1 person, 282.2ms\n",
      "0: 480x640 1 person, 297.2ms\n",
      "0: 480x640 1 person, 273.3ms\n",
      "0: 480x640 1 person, 321.5ms\n",
      "0: 480x640 1 person, 313.4ms\n",
      "0: 480x640 1 person, 290.2ms\n",
      "0: 480x640 1 person, 270.3ms\n",
      "0: 480x640 1 person, 288.2ms\n",
      "0: 480x640 1 person, 291.2ms\n",
      "0: 480x640 1 person, 273.3ms\n",
      "0: 480x640 1 person, 277.3ms\n",
      "0: 480x640 1 person, 280.3ms\n",
      "0: 480x640 1 person, 259.3ms\n",
      "0: 480x640 1 person, 282.2ms\n",
      "Speed: 1.1ms pre-process, 277.2ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Detect trực tiếp từ camera\n",
    "!python detect.py --source 0 --weights yolov5s.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train trên bộ dữ liệu panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=../custom_dataset/custom_model.yaml, data=../custom_dataset/custom_dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5  runs in Weights & Biases\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_model summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...:   0%|          | 0/175 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...1 found, 0 missing, 0 empty, 0 corrupt:   1%|          | 1/175 [00:08<23:14,  8.02s/it]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...168 found, 0 missing, 0 empty, 0 corrupt:  96%|█████████▌| 168/175 [00:08<00:00, 29.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...175 found, 0 missing, 0 empty, 0 corrupt: 100%|██████████| 175/175 [00:08<00:00, 21.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Cache directory E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\train.cache.npy' -> 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\train.cache'\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\valid' images and labels...:   0%|          | 0/37 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\valid' images and labels...1 found, 0 missing, 0 empty, 0 corrupt:   3%|▎         | 1/37 [00:11<06:51, 11.43s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\valid' images and labels...37 found, 0 missing, 0 empty, 0 corrupt: 100%|██████████| 37/37 [00:11<00:00,  3.22it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Cache directory E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\valid.cache.npy' -> 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\valid.cache'\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.94 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp3\\labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "       0/2        0G     0.119   0.02708         0        69       416:   0%|          | 0/11 [00:06<?, ?it/s]\n",
      "       0/2        0G     0.119   0.02708         0        69       416:   9%|▉         | 1/11 [00:11<01:51, 11.11s/it]\n",
      "       0/2        0G    0.1193   0.03047         0       104       416:   9%|▉         | 1/11 [00:17<01:51, 11.11s/it]\n",
      "       0/2        0G    0.1193   0.03047         0       104       416:  18%|█▊        | 2/11 [00:18<01:17,  8.63s/it]\n",
      "       0/2        0G    0.1187    0.0279         0        50       416:  18%|█▊        | 2/11 [00:24<01:17,  8.63s/it]\n",
      "       0/2        0G    0.1187    0.0279         0        50       416:  27%|██▋       | 3/11 [00:24<01:01,  7.75s/it]\n",
      "       0/2        0G    0.1191   0.02884         0       103       416:  27%|██▋       | 3/11 [00:31<01:01,  7.75s/it]\n",
      "       0/2        0G    0.1191   0.02884         0       103       416:  36%|███▋      | 4/11 [00:31<00:51,  7.32s/it]\n",
      "       0/2        0G    0.1199   0.02706         0        43       416:  36%|███▋      | 4/11 [00:38<00:51,  7.32s/it]\n",
      "       0/2        0G    0.1199   0.02706         0        43       416:  45%|████▌     | 5/11 [00:38<00:42,  7.11s/it]\n",
      "       0/2        0G    0.1197   0.02797         0        87       416:  45%|████▌     | 5/11 [00:44<00:42,  7.11s/it]\n",
      "       0/2        0G    0.1197   0.02797         0        87       416:  55%|█████▍    | 6/11 [00:44<00:34,  6.96s/it]\n",
      "       0/2        0G    0.1199   0.02716         0        46       416:  55%|█████▍    | 6/11 [00:51<00:34,  6.96s/it]\n",
      "       0/2        0G    0.1199   0.02716         0        46       416:  64%|██████▎   | 7/11 [00:51<00:27,  6.86s/it]\n",
      "       0/2        0G    0.1195   0.02712         0        66       416:  64%|██████▎   | 7/11 [00:58<00:27,  6.86s/it]\n",
      "       0/2        0G    0.1195   0.02712         0        66       416:  73%|███████▎  | 8/11 [00:58<00:20,  6.80s/it]\n",
      "       0/2        0G    0.1186   0.02819         0        88       416:  73%|███████▎  | 8/11 [01:04<00:20,  6.80s/it]\n",
      "       0/2        0G    0.1186   0.02819         0        88       416:  82%|████████▏ | 9/11 [01:04<00:13,  6.77s/it]\n",
      "       0/2        0G    0.1185   0.02925         0       126       416:  82%|████████▏ | 9/11 [01:11<00:13,  6.77s/it]\n",
      "       0/2        0G    0.1185   0.02925         0       126       416:  91%|█████████ | 10/11 [01:11<00:06,  6.72s/it]\n",
      "       0/2        0G    0.1179   0.02953         0        71       416:  91%|█████████ | 10/11 [01:17<00:06,  6.72s/it]\n",
      "       0/2        0G    0.1179   0.02953         0        71       416: 100%|██████████| 11/11 [01:17<00:00,  6.61s/it]\n",
      "       0/2        0G    0.1179   0.02953         0        71       416: 100%|██████████| 11/11 [01:17<00:00,  7.07s/it]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.30s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.35s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]\n",
      "                 all         37         58    0.00333      0.103    0.00729     0.0013\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "       1/2        0G    0.1159    0.0342         0        95       416:   0%|          | 0/11 [00:06<?, ?it/s]\n",
      "       1/2        0G    0.1159    0.0342         0        95       416:   9%|▉         | 1/11 [00:06<01:09,  6.93s/it]\n",
      "       1/2        0G     0.112   0.03371         0        73       416:   9%|▉         | 1/11 [00:13<01:09,  6.93s/it]\n",
      "       1/2        0G     0.112   0.03371         0        73       416:  18%|█▊        | 2/11 [00:13<01:02,  6.91s/it]\n",
      "       1/2        0G     0.111   0.03389         0        82       416:  18%|█▊        | 2/11 [00:20<01:02,  6.91s/it]\n",
      "       1/2        0G     0.111   0.03389         0        82       416:  27%|██▋       | 3/11 [00:20<00:54,  6.80s/it]\n",
      "       1/2        0G    0.1107   0.03377         0        73       416:  27%|██▋       | 3/11 [00:27<00:54,  6.80s/it]\n",
      "       1/2        0G    0.1107   0.03377         0        73       416:  36%|███▋      | 4/11 [00:27<00:47,  6.74s/it]\n",
      "       1/2        0G    0.1093    0.0328         0        60       416:  36%|███▋      | 4/11 [00:33<00:47,  6.74s/it]\n",
      "       1/2        0G    0.1093    0.0328         0        60       416:  45%|████▌     | 5/11 [00:33<00:40,  6.72s/it]\n",
      "       1/2        0G     0.109   0.03233         0        69       416:  45%|████▌     | 5/11 [00:40<00:40,  6.72s/it]\n",
      "       1/2        0G     0.109   0.03233         0        69       416:  55%|█████▍    | 6/11 [00:40<00:33,  6.70s/it]\n",
      "       1/2        0G    0.1082   0.03234         0        69       416:  55%|█████▍    | 6/11 [00:47<00:33,  6.70s/it]\n",
      "       1/2        0G    0.1082   0.03234         0        69       416:  64%|██████▎   | 7/11 [00:47<00:26,  6.66s/it]\n",
      "       1/2        0G    0.1077   0.03321         0        87       416:  64%|██████▎   | 7/11 [00:53<00:26,  6.66s/it]\n",
      "       1/2        0G    0.1077   0.03321         0        87       416:  73%|███████▎  | 8/11 [00:53<00:20,  6.67s/it]\n",
      "       1/2        0G    0.1069   0.03314         0        66       416:  73%|███████▎  | 8/11 [01:00<00:20,  6.67s/it]\n",
      "       1/2        0G    0.1069   0.03314         0        66       416:  82%|████████▏ | 9/11 [01:00<00:13,  6.64s/it]\n",
      "       1/2        0G    0.1067   0.03433         0       113       416:  82%|████████▏ | 9/11 [01:06<00:13,  6.64s/it]\n",
      "       1/2        0G    0.1067   0.03433         0       113       416:  91%|█████████ | 10/11 [01:06<00:06,  6.64s/it]\n",
      "       1/2        0G    0.1059   0.03413         0        60       416:  91%|█████████ | 10/11 [01:13<00:06,  6.64s/it]\n",
      "       1/2        0G    0.1059   0.03413         0        60       416: 100%|██████████| 11/11 [01:13<00:00,  6.52s/it]\n",
      "       1/2        0G    0.1059   0.03413         0        60       416: 100%|██████████| 11/11 [01:13<00:00,  6.66s/it]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.42s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.47s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]\n",
      "                 all         37         58      0.133      0.069     0.0331    0.00681\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "       2/2        0G    0.1004    0.0259         0        49       416:   0%|          | 0/11 [00:06<?, ?it/s]\n",
      "       2/2        0G    0.1004    0.0259         0        49       416:   9%|▉         | 1/11 [00:06<01:06,  6.61s/it]\n",
      "       2/2        0G    0.1037   0.03419         0       117       416:   9%|▉         | 1/11 [00:13<01:06,  6.61s/it]\n",
      "       2/2        0G    0.1037   0.03419         0       117       416:  18%|█▊        | 2/11 [00:13<00:59,  6.58s/it]\n",
      "       2/2        0G    0.1032   0.03496         0        76       416:  18%|█▊        | 2/11 [00:19<00:59,  6.58s/it]\n",
      "       2/2        0G    0.1032   0.03496         0        76       416:  27%|██▋       | 3/11 [00:19<00:52,  6.57s/it]\n",
      "       2/2        0G     0.101   0.03803         0        95       416:  27%|██▋       | 3/11 [00:26<00:52,  6.57s/it]\n",
      "       2/2        0G     0.101   0.03803         0        95       416:  36%|███▋      | 4/11 [00:26<00:46,  6.58s/it]\n",
      "       2/2        0G   0.09982   0.03802         0        72       416:  36%|███▋      | 4/11 [00:33<00:46,  6.58s/it]\n",
      "       2/2        0G   0.09982   0.03802         0        72       416:  45%|████▌     | 5/11 [00:33<00:39,  6.64s/it]\n",
      "       2/2        0G   0.09943    0.0372         0        63       416:  45%|████▌     | 5/11 [00:39<00:39,  6.64s/it]\n",
      "       2/2        0G   0.09943    0.0372         0        63       416:  55%|█████▍    | 6/11 [00:39<00:33,  6.66s/it]\n",
      "       2/2        0G   0.09941   0.03628         0        64       416:  55%|█████▍    | 6/11 [00:46<00:33,  6.66s/it]\n",
      "       2/2        0G   0.09941   0.03628         0        64       416:  64%|██████▎   | 7/11 [00:46<00:26,  6.70s/it]\n",
      "       2/2        0G   0.09826   0.03554         0        56       416:  64%|██████▎   | 7/11 [00:53<00:26,  6.70s/it]\n",
      "       2/2        0G   0.09826   0.03554         0        56       416:  73%|███████▎  | 8/11 [00:53<00:20,  6.68s/it]\n",
      "       2/2        0G   0.09843   0.03608         0        87       416:  73%|███████▎  | 8/11 [00:59<00:20,  6.68s/it]\n",
      "       2/2        0G   0.09843   0.03608         0        87       416:  82%|████████▏ | 9/11 [00:59<00:13,  6.66s/it]\n",
      "       2/2        0G   0.09729   0.03595         0        63       416:  82%|████████▏ | 9/11 [01:06<00:13,  6.66s/it]\n",
      "       2/2        0G   0.09729   0.03595         0        63       416:  91%|█████████ | 10/11 [01:06<00:06,  6.64s/it]\n",
      "       2/2        0G   0.09739   0.03548         0        57       416:  91%|█████████ | 10/11 [01:12<00:06,  6.64s/it]\n",
      "       2/2        0G   0.09739   0.03548         0        57       416: 100%|██████████| 11/11 [01:12<00:00,  6.54s/it]\n",
      "       2/2        0G   0.09739   0.03548         0        57       416: 100%|██████████| 11/11 [01:12<00:00,  6.61s/it]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.22s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]\n",
      "                 all         37         58      0.156     0.0862     0.0279    0.00992\n",
      "\n",
      "3 epochs completed in 0.069 hours.\n",
      "Optimizer stripped from runs\\train\\exp3\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\exp3\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating runs\\train\\exp3\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "custom_model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.04s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.24s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]\n",
      "                 all         37         58      0.163     0.0862     0.0268    0.00953\n",
      "Results saved to \u001b[1mruns\\train\\exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Trước tiên hãy download bộ dữ liệu về (link trên github)\n",
    "# Và để đúng đường dẫn như ảnh trên github\n",
    "# Các bạn có thể thay đổi nó nhưng hay đảm bảo rằng:\n",
    "# + Để đường dẫn cho đúng tại phần --data ở cell bên dưới\n",
    "# + Mọi đường dẫn ở cell bên dưới và đường dẫn tập train, val bên trong file custom_dataset.yaml đều đúng\n",
    "\n",
    "!python train.py --img 416 --batch 16 --epochs 3 --data ../custom_dataset/custom_dataset.yaml --cfg ../custom_dataset/custom_model.yaml --weights yolov5s.pt --device cpu\n",
    " # Nếu chạy trên GPU thì thay đổi --device cpu thành --device 0 hoặc không cần --device cũng được\n",
    " # Các bạn có thể tăng số epochs nên, ở đây mình để 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/custom_model12/weights/best.pt'], source=../custom_dataset/images_and_labels/images/test, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "image 1/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_001.jpg: 448x640 2 pandas, 272.4ms\n",
      "image 2/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_002.jpg: 640x640 1 panda, 399.0ms\n",
      "image 3/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_003.jpg: 640x576 3 pandas, 344.6ms\n",
      "image 4/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_004.jpg: 448x640 10 pandas, 250.1ms\n",
      "image 5/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_005.jpg: 480x640 2 pandas, 231.0ms\n",
      "image 6/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_006.jpg: 480x640 2 pandas, 246.9ms\n",
      "image 7/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_007.jpg: 640x640 1 panda, 345.5ms\n",
      "image 8/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_008.jpg: 448x640 1 panda, 250.1ms\n",
      "image 9/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_009.jpg: 480x640 5 pandas, 252.0ms\n",
      "image 10/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_010.jpg: 448x640 1 panda, 225.2ms\n",
      "image 11/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_011.jpg: 480x640 1 panda, 468.4ms\n",
      "image 12/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_012.jpg: 640x480 2 pandas, 482.1ms\n",
      "image 13/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_013.jpg: 480x640 2 pandas, 455.8ms\n",
      "image 14/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_014.jpg: 448x640 2 pandas, 423.7ms\n",
      "image 15/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_015.jpg: 640x384 1 panda, 374.9ms\n",
      "image 16/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_016.jpg: 480x640 1 panda, 453.6ms\n",
      "image 17/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_017.jpg: 640x640 2 pandas, 574.9ms\n",
      "image 18/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_018.jpg: 480x640 11 pandas, 509.6ms\n",
      "image 19/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_019.jpg: 640x480 1 panda, 472.5ms\n",
      "image 20/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_020.jpg: 448x640 1 panda, 444.3ms\n",
      "image 21/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_021.jpg: 448x640 (no detections), 333.2ms\n",
      "image 22/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_022.jpg: 448x640 2 pandas, 277.0ms\n",
      "image 23/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_023.jpg: 640x480 1 panda, 283.3ms\n",
      "image 24/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_024.jpg: 640x608 1 panda, 358.9ms\n",
      "image 25/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_025.jpg: 448x640 44 pandas, 356.6ms\n",
      "image 26/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_026.jpg: 480x640 2 pandas, 247.4ms\n",
      "image 27/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_027.jpg: 352x640 1 panda, 190.3ms\n",
      "image 28/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_028.jpg: 640x608 1 panda, 298.3ms\n",
      "image 29/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_029.jpg: 640x448 (no detections), 273.0ms\n",
      "image 30/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_030.jpg: 448x640 3 pandas, 270.8ms\n",
      "image 31/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_031.jpg: 448x640 1 panda, 257.3ms\n",
      "image 32/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_032.jpg: 448x640 1 panda, 253.5ms\n",
      "image 33/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_033.jpg: 480x640 2 pandas, 256.6ms\n",
      "image 34/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_034.jpg: 640x448 1 panda, 223.2ms\n",
      "image 35/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_035.jpg: 640x640 6 pandas, 285.4ms\n",
      "image 36/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_036.jpg: 480x640 4 pandas, 249.3ms\n",
      "image 37/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_037.jpg: 640x544 1 panda, 272.7ms\n",
      "image 38/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_038.jpg: 448x640 1 panda, 248.0ms\n",
      "Speed: 1.6ms pre-process, 326.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Giờ đã có model của riêng bạn\n",
    "# Hãy chạy file detect.py với weights vừa train được để xem kết quả, detect trên tập ảnh test\n",
    "!python detect.py --source ../custom_dataset/images_and_labels/images/test --weights runs/train/custom_model12/weights/best.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/custom_model12/weights/best.pt'], source=0, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "0: 480x640 3 pandas, 434.8ms\n",
      "0: 480x640 3 pandas, 279.3ms\n",
      "0: 480x640 3 pandas, 248.0ms\n",
      "0: 480x640 3 pandas, 252.5ms\n",
      "0: 480x640 3 pandas, 266.7ms\n",
      "0: 480x640 3 pandas, 265.5ms\n",
      "0: 480x640 3 pandas, 266.6ms\n",
      "0: 480x640 4 pandas, 283.1ms\n",
      "0: 480x640 3 pandas, 294.4ms\n",
      "0: 480x640 3 pandas, 264.6ms\n",
      "0: 480x640 3 pandas, 273.9ms\n",
      "0: 480x640 3 pandas, 264.9ms\n",
      "0: 480x640 3 pandas, 267.0ms\n",
      "0: 480x640 3 pandas, 265.9ms\n",
      "0: 480x640 3 pandas, 258.9ms\n",
      "0: 480x640 3 pandas, 251.4ms\n",
      "0: 480x640 3 pandas, 274.0ms\n",
      "0: 480x640 3 pandas, 271.1ms\n",
      "0: 480x640 5 pandas, 278.7ms\n",
      "0: 480x640 5 pandas, 288.1ms\n",
      "0: 480x640 5 pandas, 265.1ms\n",
      "0: 480x640 5 pandas, 266.7ms\n",
      "0: 480x640 5 pandas, 239.6ms\n",
      "0: 480x640 5 pandas, 245.8ms\n",
      "0: 480x640 5 pandas, 253.5ms\n",
      "0: 480x640 6 pandas, 260.6ms\n",
      "0: 480x640 6 pandas, 261.3ms\n",
      "0: 480x640 6 pandas, 250.1ms\n",
      "0: 480x640 5 pandas, 260.5ms\n",
      "0: 480x640 5 pandas, 266.3ms\n",
      "0: 480x640 5 pandas, 268.6ms\n",
      "0: 480x640 5 pandas, 274.4ms\n",
      "0: 480x640 5 pandas, 272.6ms\n",
      "0: 480x640 6 pandas, 266.7ms\n",
      "0: 480x640 6 pandas, 256.6ms\n",
      "0: 480x640 7 pandas, 249.8ms\n",
      "0: 480x640 6 pandas, 255.3ms\n",
      "0: 480x640 6 pandas, 276.4ms\n",
      "0: 480x640 5 pandas, 251.7ms\n",
      "0: 480x640 6 pandas, 258.9ms\n",
      "0: 480x640 5 pandas, 251.8ms\n",
      "Speed: 0.9ms pre-process, 268.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Vẫn là detect nhưng detect trực tiếp từ camera\n",
    "!python detect.py --source 0 --weights runs/train/custom_model12/weights/best.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúc các bạn thành công !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

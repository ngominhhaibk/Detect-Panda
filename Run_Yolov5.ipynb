{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python38\\lib\\site-packages\\torch\\hub.py:266: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\HP/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-8-21 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6995a74be04072843a2dd1fd072565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 1051.1ms pre-process, 392.5ms inference, 11.1ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n",
    "\n",
    "# Images\n",
    "img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "\n",
    "# Results\n",
    "results.print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --source 0  # webcam\n",
    "                        # img.jpg  # image\n",
    "                        #   vid.mp4  # video\n",
    "                        #   path/  # directory\n",
    "                        #   'path/*.jpg'  # glob\n",
    "                        #   'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                        #   'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/2 E:\\AI_ML_DL\\Yolo\\yolov5\\data\\images\\bus.jpg: 640x480 4 persons, 1 bus, 327.1ms\n",
      "image 2/2 E:\\AI_ML_DL\\Yolo\\yolov5\\data\\images\\zidane.jpg: 384x640 2 persons, 2 ties, 254.3ms\n",
      "Speed: 1.8ms pre-process, 290.7ms inference, 6.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source data/images --weights yolov5s.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=0, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "0: 480x640 1 person, 485.2ms\n",
      "0: 480x640 1 person, 301.3ms\n",
      "0: 480x640 1 person, 317.5ms\n",
      "0: 480x640 1 person, 294.7ms\n",
      "0: 480x640 1 person, 1 cell phone, 277.4ms\n",
      "0: 480x640 1 person, 1 cell phone, 260.4ms\n",
      "0: 480x640 1 person, 1 cell phone, 269.7ms\n",
      "0: 480x640 1 person, 1 cell phone, 267.3ms\n",
      "0: 480x640 1 person, 1 cell phone, 284.9ms\n",
      "0: 480x640 1 person, 284.4ms\n",
      "0: 480x640 1 person, 291.0ms\n",
      "0: 480x640 1 person, 325.4ms\n",
      "0: 480x640 1 person, 266.8ms\n",
      "0: 480x640 1 person, 271.7ms\n",
      "Speed: 0.8ms pre-process, 299.8ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source 0 --weights yolov5s.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 5)) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 6)) (1.23.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 8)) (9.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 10)) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 11)) (1.9.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 12)) (1.12.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 13)) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 14)) (4.64.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 15)) (3.19.4)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 18)) (2.10.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 23)) (1.4.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 24)) (0.11.2)\n",
      "Requirement already satisfied: ipython in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 38)) (8.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 39)) (5.9.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 40)) (0.1.1.post2207130030)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python\\python38\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python\\python38\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python38\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python38\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python\\python38\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python\\python38\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python\\python38\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 14)) (0.4.5)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.9.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.3.7)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (47.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.47.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\python38\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (3.0.30)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (5.3.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\python\\python38\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (4.4.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (0.3.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from ipython->-r requirements.txt (line 38)) (2.12.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.12.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 38)) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (2.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=../custom_dataset/custom_model.yaml, data=../custom_dataset/custom_dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5  runs in Weights & Biases\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_model summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...:   0%|          | 0/175 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...1 found, 0 missing, 0 empty, 0 corrupt:   1%|          | 1/175 [00:08<23:14,  8.02s/it]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...168 found, 0 missing, 0 empty, 0 corrupt:  96%|█████████▌| 168/175 [00:08<00:00, 29.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\train' images and labels...175 found, 0 missing, 0 empty, 0 corrupt: 100%|██████████| 175/175 [00:08<00:00, 21.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Cache directory E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\train.cache.npy' -> 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\train.cache'\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\valid' images and labels...:   0%|          | 0/37 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\valid' images and labels...1 found, 0 missing, 0 empty, 0 corrupt:   3%|▎         | 1/37 [00:11<06:51, 11.43s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels\\valid' images and labels...37 found, 0 missing, 0 empty, 0 corrupt: 100%|██████████| 37/37 [00:11<00:00,  3.22it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Cache directory E:\\AI_ML_DL\\Yolo\\yolov5\\..\\custom_dataset\\images_and_labels\\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\valid.cache.npy' -> 'E:\\\\AI_ML_DL\\\\Yolo\\\\yolov5\\\\..\\\\custom_dataset\\\\images_and_labels\\\\labels\\\\valid.cache'\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.94 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp3\\labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "       0/2        0G     0.119   0.02708         0        69       416:   0%|          | 0/11 [00:06<?, ?it/s]\n",
      "       0/2        0G     0.119   0.02708         0        69       416:   9%|▉         | 1/11 [00:11<01:51, 11.11s/it]\n",
      "       0/2        0G    0.1193   0.03047         0       104       416:   9%|▉         | 1/11 [00:17<01:51, 11.11s/it]\n",
      "       0/2        0G    0.1193   0.03047         0       104       416:  18%|█▊        | 2/11 [00:18<01:17,  8.63s/it]\n",
      "       0/2        0G    0.1187    0.0279         0        50       416:  18%|█▊        | 2/11 [00:24<01:17,  8.63s/it]\n",
      "       0/2        0G    0.1187    0.0279         0        50       416:  27%|██▋       | 3/11 [00:24<01:01,  7.75s/it]\n",
      "       0/2        0G    0.1191   0.02884         0       103       416:  27%|██▋       | 3/11 [00:31<01:01,  7.75s/it]\n",
      "       0/2        0G    0.1191   0.02884         0       103       416:  36%|███▋      | 4/11 [00:31<00:51,  7.32s/it]\n",
      "       0/2        0G    0.1199   0.02706         0        43       416:  36%|███▋      | 4/11 [00:38<00:51,  7.32s/it]\n",
      "       0/2        0G    0.1199   0.02706         0        43       416:  45%|████▌     | 5/11 [00:38<00:42,  7.11s/it]\n",
      "       0/2        0G    0.1197   0.02797         0        87       416:  45%|████▌     | 5/11 [00:44<00:42,  7.11s/it]\n",
      "       0/2        0G    0.1197   0.02797         0        87       416:  55%|█████▍    | 6/11 [00:44<00:34,  6.96s/it]\n",
      "       0/2        0G    0.1199   0.02716         0        46       416:  55%|█████▍    | 6/11 [00:51<00:34,  6.96s/it]\n",
      "       0/2        0G    0.1199   0.02716         0        46       416:  64%|██████▎   | 7/11 [00:51<00:27,  6.86s/it]\n",
      "       0/2        0G    0.1195   0.02712         0        66       416:  64%|██████▎   | 7/11 [00:58<00:27,  6.86s/it]\n",
      "       0/2        0G    0.1195   0.02712         0        66       416:  73%|███████▎  | 8/11 [00:58<00:20,  6.80s/it]\n",
      "       0/2        0G    0.1186   0.02819         0        88       416:  73%|███████▎  | 8/11 [01:04<00:20,  6.80s/it]\n",
      "       0/2        0G    0.1186   0.02819         0        88       416:  82%|████████▏ | 9/11 [01:04<00:13,  6.77s/it]\n",
      "       0/2        0G    0.1185   0.02925         0       126       416:  82%|████████▏ | 9/11 [01:11<00:13,  6.77s/it]\n",
      "       0/2        0G    0.1185   0.02925         0       126       416:  91%|█████████ | 10/11 [01:11<00:06,  6.72s/it]\n",
      "       0/2        0G    0.1179   0.02953         0        71       416:  91%|█████████ | 10/11 [01:17<00:06,  6.72s/it]\n",
      "       0/2        0G    0.1179   0.02953         0        71       416: 100%|██████████| 11/11 [01:17<00:00,  6.61s/it]\n",
      "       0/2        0G    0.1179   0.02953         0        71       416: 100%|██████████| 11/11 [01:17<00:00,  7.07s/it]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.30s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.35s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]\n",
      "                 all         37         58    0.00333      0.103    0.00729     0.0013\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "       1/2        0G    0.1159    0.0342         0        95       416:   0%|          | 0/11 [00:06<?, ?it/s]\n",
      "       1/2        0G    0.1159    0.0342         0        95       416:   9%|▉         | 1/11 [00:06<01:09,  6.93s/it]\n",
      "       1/2        0G     0.112   0.03371         0        73       416:   9%|▉         | 1/11 [00:13<01:09,  6.93s/it]\n",
      "       1/2        0G     0.112   0.03371         0        73       416:  18%|█▊        | 2/11 [00:13<01:02,  6.91s/it]\n",
      "       1/2        0G     0.111   0.03389         0        82       416:  18%|█▊        | 2/11 [00:20<01:02,  6.91s/it]\n",
      "       1/2        0G     0.111   0.03389         0        82       416:  27%|██▋       | 3/11 [00:20<00:54,  6.80s/it]\n",
      "       1/2        0G    0.1107   0.03377         0        73       416:  27%|██▋       | 3/11 [00:27<00:54,  6.80s/it]\n",
      "       1/2        0G    0.1107   0.03377         0        73       416:  36%|███▋      | 4/11 [00:27<00:47,  6.74s/it]\n",
      "       1/2        0G    0.1093    0.0328         0        60       416:  36%|███▋      | 4/11 [00:33<00:47,  6.74s/it]\n",
      "       1/2        0G    0.1093    0.0328         0        60       416:  45%|████▌     | 5/11 [00:33<00:40,  6.72s/it]\n",
      "       1/2        0G     0.109   0.03233         0        69       416:  45%|████▌     | 5/11 [00:40<00:40,  6.72s/it]\n",
      "       1/2        0G     0.109   0.03233         0        69       416:  55%|█████▍    | 6/11 [00:40<00:33,  6.70s/it]\n",
      "       1/2        0G    0.1082   0.03234         0        69       416:  55%|█████▍    | 6/11 [00:47<00:33,  6.70s/it]\n",
      "       1/2        0G    0.1082   0.03234         0        69       416:  64%|██████▎   | 7/11 [00:47<00:26,  6.66s/it]\n",
      "       1/2        0G    0.1077   0.03321         0        87       416:  64%|██████▎   | 7/11 [00:53<00:26,  6.66s/it]\n",
      "       1/2        0G    0.1077   0.03321         0        87       416:  73%|███████▎  | 8/11 [00:53<00:20,  6.67s/it]\n",
      "       1/2        0G    0.1069   0.03314         0        66       416:  73%|███████▎  | 8/11 [01:00<00:20,  6.67s/it]\n",
      "       1/2        0G    0.1069   0.03314         0        66       416:  82%|████████▏ | 9/11 [01:00<00:13,  6.64s/it]\n",
      "       1/2        0G    0.1067   0.03433         0       113       416:  82%|████████▏ | 9/11 [01:06<00:13,  6.64s/it]\n",
      "       1/2        0G    0.1067   0.03433         0       113       416:  91%|█████████ | 10/11 [01:06<00:06,  6.64s/it]\n",
      "       1/2        0G    0.1059   0.03413         0        60       416:  91%|█████████ | 10/11 [01:13<00:06,  6.64s/it]\n",
      "       1/2        0G    0.1059   0.03413         0        60       416: 100%|██████████| 11/11 [01:13<00:00,  6.52s/it]\n",
      "       1/2        0G    0.1059   0.03413         0        60       416: 100%|██████████| 11/11 [01:13<00:00,  6.66s/it]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.42s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.47s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]\n",
      "                 all         37         58      0.133      0.069     0.0331    0.00681\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "       2/2        0G    0.1004    0.0259         0        49       416:   0%|          | 0/11 [00:06<?, ?it/s]\n",
      "       2/2        0G    0.1004    0.0259         0        49       416:   9%|▉         | 1/11 [00:06<01:06,  6.61s/it]\n",
      "       2/2        0G    0.1037   0.03419         0       117       416:   9%|▉         | 1/11 [00:13<01:06,  6.61s/it]\n",
      "       2/2        0G    0.1037   0.03419         0       117       416:  18%|█▊        | 2/11 [00:13<00:59,  6.58s/it]\n",
      "       2/2        0G    0.1032   0.03496         0        76       416:  18%|█▊        | 2/11 [00:19<00:59,  6.58s/it]\n",
      "       2/2        0G    0.1032   0.03496         0        76       416:  27%|██▋       | 3/11 [00:19<00:52,  6.57s/it]\n",
      "       2/2        0G     0.101   0.03803         0        95       416:  27%|██▋       | 3/11 [00:26<00:52,  6.57s/it]\n",
      "       2/2        0G     0.101   0.03803         0        95       416:  36%|███▋      | 4/11 [00:26<00:46,  6.58s/it]\n",
      "       2/2        0G   0.09982   0.03802         0        72       416:  36%|███▋      | 4/11 [00:33<00:46,  6.58s/it]\n",
      "       2/2        0G   0.09982   0.03802         0        72       416:  45%|████▌     | 5/11 [00:33<00:39,  6.64s/it]\n",
      "       2/2        0G   0.09943    0.0372         0        63       416:  45%|████▌     | 5/11 [00:39<00:39,  6.64s/it]\n",
      "       2/2        0G   0.09943    0.0372         0        63       416:  55%|█████▍    | 6/11 [00:39<00:33,  6.66s/it]\n",
      "       2/2        0G   0.09941   0.03628         0        64       416:  55%|█████▍    | 6/11 [00:46<00:33,  6.66s/it]\n",
      "       2/2        0G   0.09941   0.03628         0        64       416:  64%|██████▎   | 7/11 [00:46<00:26,  6.70s/it]\n",
      "       2/2        0G   0.09826   0.03554         0        56       416:  64%|██████▎   | 7/11 [00:53<00:26,  6.70s/it]\n",
      "       2/2        0G   0.09826   0.03554         0        56       416:  73%|███████▎  | 8/11 [00:53<00:20,  6.68s/it]\n",
      "       2/2        0G   0.09843   0.03608         0        87       416:  73%|███████▎  | 8/11 [00:59<00:20,  6.68s/it]\n",
      "       2/2        0G   0.09843   0.03608         0        87       416:  82%|████████▏ | 9/11 [00:59<00:13,  6.66s/it]\n",
      "       2/2        0G   0.09729   0.03595         0        63       416:  82%|████████▏ | 9/11 [01:06<00:13,  6.66s/it]\n",
      "       2/2        0G   0.09729   0.03595         0        63       416:  91%|█████████ | 10/11 [01:06<00:06,  6.64s/it]\n",
      "       2/2        0G   0.09739   0.03548         0        57       416:  91%|█████████ | 10/11 [01:12<00:06,  6.64s/it]\n",
      "       2/2        0G   0.09739   0.03548         0        57       416: 100%|██████████| 11/11 [01:12<00:00,  6.54s/it]\n",
      "       2/2        0G   0.09739   0.03548         0        57       416: 100%|██████████| 11/11 [01:12<00:00,  6.61s/it]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.22s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]\n",
      "                 all         37         58      0.156     0.0862     0.0279    0.00992\n",
      "\n",
      "3 epochs completed in 0.069 hours.\n",
      "Optimizer stripped from runs\\train\\exp3\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\exp3\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating runs\\train\\exp3\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "custom_model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING: NMS time limit 1.260s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 1/2 [00:06<00:06,  6.04s/it]WARNING: NMS time limit 0.450s exceeded\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.24s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]\n",
      "                 all         37         58      0.163     0.0862     0.0268    0.00953\n",
      "Results saved to \u001b[1mruns\\train\\exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 416 --batch 16 --epochs 3 --data ../custom_dataset/custom_dataset.yaml --cfg ../custom_dataset/custom_model.yaml --weights yolov5s.pt --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter format not correct - \"rain\".\n"
     ]
    }
   ],
   "source": [
    "%ls runs/train/custom_model12/weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/custom_model12/weights/best.pt'], source=../custom_dataset/images_and_labels/images/test, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "image 1/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_001.jpg: 448x640 2 pandas, 272.4ms\n",
      "image 2/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_002.jpg: 640x640 1 panda, 399.0ms\n",
      "image 3/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_003.jpg: 640x576 3 pandas, 344.6ms\n",
      "image 4/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_004.jpg: 448x640 10 pandas, 250.1ms\n",
      "image 5/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_005.jpg: 480x640 2 pandas, 231.0ms\n",
      "image 6/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_006.jpg: 480x640 2 pandas, 246.9ms\n",
      "image 7/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_007.jpg: 640x640 1 panda, 345.5ms\n",
      "image 8/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_008.jpg: 448x640 1 panda, 250.1ms\n",
      "image 9/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_009.jpg: 480x640 5 pandas, 252.0ms\n",
      "image 10/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_010.jpg: 448x640 1 panda, 225.2ms\n",
      "image 11/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_011.jpg: 480x640 1 panda, 468.4ms\n",
      "image 12/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_012.jpg: 640x480 2 pandas, 482.1ms\n",
      "image 13/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_013.jpg: 480x640 2 pandas, 455.8ms\n",
      "image 14/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_014.jpg: 448x640 2 pandas, 423.7ms\n",
      "image 15/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_015.jpg: 640x384 1 panda, 374.9ms\n",
      "image 16/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_016.jpg: 480x640 1 panda, 453.6ms\n",
      "image 17/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_017.jpg: 640x640 2 pandas, 574.9ms\n",
      "image 18/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_018.jpg: 480x640 11 pandas, 509.6ms\n",
      "image 19/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_019.jpg: 640x480 1 panda, 472.5ms\n",
      "image 20/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_020.jpg: 448x640 1 panda, 444.3ms\n",
      "image 21/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_021.jpg: 448x640 (no detections), 333.2ms\n",
      "image 22/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_022.jpg: 448x640 2 pandas, 277.0ms\n",
      "image 23/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_023.jpg: 640x480 1 panda, 283.3ms\n",
      "image 24/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_024.jpg: 640x608 1 panda, 358.9ms\n",
      "image 25/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_025.jpg: 448x640 44 pandas, 356.6ms\n",
      "image 26/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_026.jpg: 480x640 2 pandas, 247.4ms\n",
      "image 27/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_027.jpg: 352x640 1 panda, 190.3ms\n",
      "image 28/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_028.jpg: 640x608 1 panda, 298.3ms\n",
      "image 29/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_029.jpg: 640x448 (no detections), 273.0ms\n",
      "image 30/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_030.jpg: 448x640 3 pandas, 270.8ms\n",
      "image 31/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_031.jpg: 448x640 1 panda, 257.3ms\n",
      "image 32/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_032.jpg: 448x640 1 panda, 253.5ms\n",
      "image 33/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_033.jpg: 480x640 2 pandas, 256.6ms\n",
      "image 34/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_034.jpg: 640x448 1 panda, 223.2ms\n",
      "image 35/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_035.jpg: 640x640 6 pandas, 285.4ms\n",
      "image 36/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_036.jpg: 480x640 4 pandas, 249.3ms\n",
      "image 37/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_037.jpg: 640x544 1 panda, 272.7ms\n",
      "image 38/38 E:\\AI_ML_DL\\Yolo\\custom_dataset\\images_and_labels\\images\\test\\test_038.jpg: 448x640 1 panda, 248.0ms\n",
      "Speed: 1.6ms pre-process, 326.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source ../custom_dataset/images_and_labels/images/test --weights runs/train/custom_model12/weights/best.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/custom_model12/weights/best.pt'], source=0, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2022-8-20 Python-3.8.5 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "0: 480x640 3 pandas, 434.8ms\n",
      "0: 480x640 3 pandas, 279.3ms\n",
      "0: 480x640 3 pandas, 248.0ms\n",
      "0: 480x640 3 pandas, 252.5ms\n",
      "0: 480x640 3 pandas, 266.7ms\n",
      "0: 480x640 3 pandas, 265.5ms\n",
      "0: 480x640 3 pandas, 266.6ms\n",
      "0: 480x640 4 pandas, 283.1ms\n",
      "0: 480x640 3 pandas, 294.4ms\n",
      "0: 480x640 3 pandas, 264.6ms\n",
      "0: 480x640 3 pandas, 273.9ms\n",
      "0: 480x640 3 pandas, 264.9ms\n",
      "0: 480x640 3 pandas, 267.0ms\n",
      "0: 480x640 3 pandas, 265.9ms\n",
      "0: 480x640 3 pandas, 258.9ms\n",
      "0: 480x640 3 pandas, 251.4ms\n",
      "0: 480x640 3 pandas, 274.0ms\n",
      "0: 480x640 3 pandas, 271.1ms\n",
      "0: 480x640 5 pandas, 278.7ms\n",
      "0: 480x640 5 pandas, 288.1ms\n",
      "0: 480x640 5 pandas, 265.1ms\n",
      "0: 480x640 5 pandas, 266.7ms\n",
      "0: 480x640 5 pandas, 239.6ms\n",
      "0: 480x640 5 pandas, 245.8ms\n",
      "0: 480x640 5 pandas, 253.5ms\n",
      "0: 480x640 6 pandas, 260.6ms\n",
      "0: 480x640 6 pandas, 261.3ms\n",
      "0: 480x640 6 pandas, 250.1ms\n",
      "0: 480x640 5 pandas, 260.5ms\n",
      "0: 480x640 5 pandas, 266.3ms\n",
      "0: 480x640 5 pandas, 268.6ms\n",
      "0: 480x640 5 pandas, 274.4ms\n",
      "0: 480x640 5 pandas, 272.6ms\n",
      "0: 480x640 6 pandas, 266.7ms\n",
      "0: 480x640 6 pandas, 256.6ms\n",
      "0: 480x640 7 pandas, 249.8ms\n",
      "0: 480x640 6 pandas, 255.3ms\n",
      "0: 480x640 6 pandas, 276.4ms\n",
      "0: 480x640 5 pandas, 251.7ms\n",
      "0: 480x640 6 pandas, 258.9ms\n",
      "0: 480x640 5 pandas, 251.8ms\n",
      "Speed: 0.9ms pre-process, 268.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source 0 --weights runs/train/custom_model12/weights/best.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
